{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Geospatial\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "\n",
    "# ARIMA\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Filters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = [[-12.216796875000002,59.40036514079251],[25.576171875,59.40036514079251],[25.576171875,36.10237644873644],[-12.216796875000002,36.10237644873644],[-12.216796875000002,59.40036514079251]] # europe\n",
    "# filter_list = [[-10.898437500000002,34.59704151614417],[34.10156250000001,34.59704151614417],[34.10156250000001,-35.17380831799957],[-10.898437500000002,-35.17380831799957],[-10.898437500000002,34.59704151614417]] # africa\n",
    "# filter_list = [[-125.06835937500001,45.767522962149904],[-116.982421875,45.767522962149904],[-116.982421875,31.728167146023935],[-125.06835937500001,31.728167146023935],[-125.06835937500001,45.767522962149904]] # california\n",
    "filters_str = json.dumps(filter_list, separators=(\",\", \":\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://127.0.0.1:9999/earthquake\")\n",
    "response_dict = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert to DataFrame</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert response to pandas - whole object\"\"\"\n",
    "eq_list = []\n",
    "for eq in response_dict['data']:\n",
    "    timestamp = datetime.datetime.fromtimestamp(eq['time']//1000)\n",
    "    dataframe_fields = {\n",
    "        \"id\": eq['id'],\n",
    "        \"mag\": eq['mag'],\n",
    "        \"time\": datetime.datetime.fromtimestamp(eq['time']//1000),\n",
    "        \"latitude\": eq['geometry']['coordinates'][1],\n",
    "        \"longitude\": eq['geometry']['coordinates'][0],\n",
    "        \"height\": eq['geometry']['coordinates'][2],\n",
    "    }\n",
    "    eq_list.append(dataframe_fields)\n",
    "\n",
    "df = pd.DataFrame(eq_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save DataFrame to Pickle</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling\n",
    "df.to_pickle('./earthquakes_with_coordinates.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load DataFrame from Pickle</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickling\n",
    "df = pd.read_pickle('./earthquakes_with_coordinates.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filter data from 1996 to 2022 (full years)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['time'].dt.year.isin(range(1996, 2023))]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save DataFrame to Pickle (1996-2022)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./earthquakes_with_coordinates_1996_2022.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load DataFrame from Pickle (1996-2022)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./earthquakes_with_coordinates_1996_2022.pkl')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filter DataFrame to Pickle >=4.0(1996-2022)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['mag'] >= 3.0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save DataFrame to Pickle >=4.0 (1996-2022)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./earthquakes_with_coordinates_1996_2022_mag_3.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load DataFrame from Pickle >=4.0 (1996-2022)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./earthquakes_with_coordinates_1996_2022_mag_3.pkl')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "filtered_df = df\n",
    "\n",
    "plt.scatter(filtered_df['time'], filtered_df['mag'], s=[3])\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get day from datetime</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['date'] = filtered_df['time'].dt.date\n",
    "df['year_month'] = df['time'].dt.to_period('M').astype(str)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Group by day and count</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count per day\n",
    "day_count = filtered_df.groupby(filtered_df['year_month']).size().reset_index(name='count')\n",
    "\n",
    "plt.plot(day_count['year_month'], day_count['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make grid for prediction</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = -180, -90, 180, 90\n",
    "\n",
    "n_cells=20\n",
    "cell_size = (xmax-xmin)/n_cells\n",
    "\n",
    "grid_cells = []\n",
    "for x0 in np.arange(xmin, xmax+cell_size, cell_size ):\n",
    "    for y0 in np.arange(ymin, ymax+cell_size, cell_size):\n",
    "        # bounds\n",
    "        x1 = x0-cell_size\n",
    "        y1 = y0+cell_size\n",
    "        grid_cells.append(shapely.geometry.box(x0, y0, x1, y1)  )\n",
    "cell = gpd.GeoDataFrame(grid_cells, columns=['geometry'], crs='epsg:4326')\n",
    "cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot all grids</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "cell.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5),\n",
    "                       subplot_kw={'projection': ccrs.Orthographic(central_longitude=180, central_latitude=0)})\n",
    "\n",
    "# Add the GeoSeries on top of the globe\n",
    "ax.set_global()\n",
    "ax.coastlines()  # Optional: add coastlines for better context\n",
    "for index, series in cell.iloc[:219].iterrows():\n",
    "   cell.iloc[[index]].geometry.to_crs(epsg=4326).plot(ax=ax, transform=ccrs.PlateCarree(), color='blue', edgecolor='black', alpha=0.5, aspect=1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save grid to Pickle</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.to_pickle('./grid_20.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load grid from Pickle</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pd.read_pickle('./grid_20.pkl')\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert latitude and longitude to POINT</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(filtered_df, geometry=gpd.points_from_xy(filtered_df['longitude'], filtered_df['latitude']), crs=\"EPSG:4326\")\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save earthquakes to Pickle</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_pickle('./earthquakes_with_coordinates_1996_2022_mag_3_20_year_month.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load earthquakes to Pickle</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf = pd.read_pickle('./earthquakes_with_coordinates_1996_2022_mag_3_20_year_month.pkl')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add Polygon index to earthquakes</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_with_polygon = gpd.sjoin(gdf, grid, how=\"left\", op=\"within\")\n",
    "gdf_with_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Group by polygon index and count</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_index_with_count_per_day = gdf_with_polygon.groupby(['index_right', 'year_month']).size().reset_index(name='count')\n",
    "polygon_index_with_count_per_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>For each Grid cell make list of all days from 1996 to 2022 and count how many earthquakes occured each day</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date range from 1996 to 2022 with monthly frequency\n",
    "date_range = pd.date_range(start='1996-01', end='2022-12', freq='M').strftime('%Y-%m')\n",
    "\n",
    "# Get unique polygon indices from grid\n",
    "unique_polygons = grid.index\n",
    "\n",
    "# Create all combinations of polygon indices and dates\n",
    "all_combinations = pd.MultiIndex.from_product([unique_polygons, date_range], \n",
    "                                            names=['index_right', 'year_month'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "# Merge with actual counts, filling NaN with 0\n",
    "complete_counts = pd.merge(all_combinations_df, \n",
    "                         polygon_index_with_count_per_day,\n",
    "                         on=['index_right', 'year_month'],\n",
    "                         how='left')\n",
    "complete_counts['count'] = complete_counts['count'].fillna(0)\n",
    "\n",
    "# Sort by index_right and date\n",
    "complete_counts = complete_counts.sort_values(['index_right', 'year_month'])\n",
    "complete_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add grid polygons based on index of polygon</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge grid polygons with complete counts\n",
    "complete_counts_with_geometry = pd.merge(\n",
    "    complete_counts,\n",
    "    grid.reset_index(),\n",
    "    left_on='index_right',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_complete = gpd.GeoDataFrame(\n",
    "    complete_counts_with_geometry, \n",
    "    geometry='geometry',\n",
    "    crs=grid.crs\n",
    ")\n",
    "\n",
    "gdf_complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save complete geodataframe (polygons and counts per day)to Pickle</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_complete.to_pickle('./grid_polygons_1996_2022_mag_3_20_with_year_month_counts.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load complete geodataframe (polygons and counts per day) from Pickle</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_complete = pd.read_pickle('./grid_polygons_1996_2022_mag_3_20_with_year_month_counts.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Select California polygon </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_polygon = gdf_complete.loc[gdf_complete['index_right'] == 202]\n",
    "california_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save California geodataframe (polygons and counts per day)to Pickle</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_polygon.to_pickle('./california_polygon_1996_2022_mag_3_20_with_year_month_counts.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load California geodataframe (polygons and counts per day) from Pickle</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_polygon = pd.read_pickle('./california_polygon_1996_2022_mag_3_20_with_year_month_counts.pkl')\n",
    "california_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_earthquakes = gdf_complete.groupby('index_right')['count'].mean().sort_values(ascending=False)\n",
    "avg_earthquakes\n",
    "\n",
    "# Get polygon with highest average\n",
    "california_polygon = gdf_complete.loc[gdf_complete['index_right'] == avg_earthquakes.index[0]]\n",
    "pd.options.display.max_rows = 10\n",
    "california_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot California polygon on map</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5),\n",
    "                       subplot_kw={'projection': ccrs.Orthographic(central_longitude=120, central_latitude=0)})\n",
    "                     #   subplot_kw={'projection': ccrs.Orthographic(central_longitude=-72, central_latitude=-36)})\n",
    "\n",
    "# Add the GeoSeries on top of the globe\n",
    "ax.set_global()\n",
    "ax.coastlines()  # Optional: add coastlines for better context\n",
    "california_polygon.head(1).plot(ax=ax, transform=ccrs.PlateCarree(), color='blue', edgecolor='black', alpha=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot California earthquakes per day</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract years from year_month and get unique values\n",
    "# Filter for just 1996\n",
    "df_1996 = california_polygon[pd.to_datetime(california_polygon['year_month']).dt.year == 1996]\n",
    "\n",
    "# Get monthly counts for 1996\n",
    "monthly_counts = df_1996.groupby('year_month')['count'].mean()\n",
    "\n",
    "# Get month numbers for x-axis\n",
    "months = pd.to_datetime(monthly_counts.index).month\n",
    "\n",
    "plt.plot(months, monthly_counts)\n",
    "plt.xlabel('Miesiąc')\n",
    "plt.ylabel('Liczba trzęsień ziemi')\n",
    "plt.title('Liczba trzęsień ziemi w kolejnych miesiącach w 1996 roku')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare data for ARIMA prediction</h3>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_arima = california_polygon[['year_month', 'count']]\n",
    "df_for_arima = df_for_arima.reset_index(drop=True)\n",
    "\n",
    "# Calculate split point at 80% of data\n",
    "split_point = int(len(df_for_arima) * 0.8)\n",
    "\n",
    "# Split into train (80%) and test (20%) sets\n",
    "train = df_for_arima[:split_point]\n",
    "test = df_for_arima[split_point:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train model with AutoARIMA</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pm.auto_arima(train['count'],\n",
    "model = pm.auto_arima(train['count'],\n",
    "                      # m=12,               # frequency of series\n",
    "                      seasonal=False,  # TRUE if seasonal series\n",
    "                      d=None,             # let model determine 'd'\n",
    "                      test='adf',         # use adftest to find optimal 'd'\n",
    "                      start_p=0, start_q=0, # minimum p and q\n",
    "                      max_p=12, max_q=12, # maximum p and q \n",
    "                      D=None,             # let model determine 'D'\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      stepwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model summary</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot predictions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = int(len(df_for_arima) * 0.2) + 1\n",
    "predicted, confint = model.predict(n_periods=test_count, return_conf_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plot = test\n",
    "predicted_plot = predicted\n",
    "print(test_plot)\n",
    "days = test_plot['year_month']\n",
    "plt.plot(df_for_arima['year_month'], df_for_arima['count'], label='Wartości rzeczywiste')\n",
    "plt.plot(days, predicted_plot.iloc[:], label='Wartości przewidziane')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_plot['count'], predicted_plot))\n",
    "print(f'Root Mean Square Error (RMSE): {rmse:.2f}')\n",
    "\n",
    "# Calculate MAE \n",
    "mae = mean_absolute_error(test_plot['count'], predicted_plot)\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
